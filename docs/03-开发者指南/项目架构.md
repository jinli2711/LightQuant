# 项目架构

本章节详细介绍 LightQuant 项目的整体架构设计，包括目录结构、模块划分、核心组件和它们之间的交互关系。理解项目架构有助于您更好地使用项目功能并进行二次开发。

## 整体架构概览

LightQuant 采用分层架构设计，从上到下依次为：应用层提供统一的运行入口和命令行接口；模型层封装了各种深度学习预测模型；数据层负责数据的加载、预处理和批处理；工具层提供通用的辅助功能。数据流从底层向上层流动，经过数据加载、模型推理、结果处理后输出。整个框架强调模块化和可扩展性，每个模块都有清晰的职责边界和标准化的接口定义，便于独立开发和测试。

框架的核心设计理念包括：模块化设计使得各组件可以独立替换和升级；统一接口确保不同模型和数据处理流程的一致性；灵活配置通过参数化设计支持各种场景需求；可扩展性提供清晰的扩展点便于添加新功能。这种设计使得 LightQuant 既可以作为一个完整的框架使用，也可以拆分成独立模块集成到其他项目中。

## 目录结构详解

### 根目录文件

项目根目录包含以下核心文件：README.md 是项目主文档，提供项目简介和使用说明；requirements.txt 列出所有 Python 依赖包及其版本；run.py 是模型训练的主入口脚本；run.sh 是模型训练的 Shell 启动脚本；run_backtest.sh 是回测的 Shell 启动脚本。这些文件构成了项目的最外层接口，用户通常从这些文件开始使用项目。

### model 模块

`model/` 目录包含所有预测模型的实现，是项目的核心模块。模型按架构类型组织：基础序列模型包括 LSTM.py（标准 LSTM）、BiLSTM.py（双向 LSTM）、BiGRU.py（双向 GRU）；注意力增强模型包括 ALSTM.py（注意力 LSTM）、Adv_LSTM.py（对抗训练 LSTM）、HAN.py（层级注意力网络）；图神经网络模型 DTML.py（动态时间记忆网络）；时序预测模型 SCINet.py（采样交叉交互网络）；多模态融合模型 StockNet.py、PEN.py（预训练金融模型）；混合模型 GAN_LSTM.py。每个模型都继承自 PyTorch 的 nn.Module 类，定义了标准的 forward 接口。

### utils 模块

`utils/` 目录包含各种工具函数和类，支持项目各个模块的功能。数据加载相关包括 price_dataloader.py（价格数据加载器）、price_news_dataloader.py（多模态数据加载器）、news_process.py（新闻数据处理工具）；预处理相关包括 util.py（通用工具函数，包括数据检查、缺失值处理、数据集划分）；特征工程包括 word2vec.py（词向量生成工具）；可视化包括 plot.py（绘图工具）；测试包括 test.py（测试脚本）。utils 模块为上层功能提供基础支撑，是项目不可或缺的部分。

### backtest 模块

`backtest/` 目录包含回测框架的实现，用于验证交易策略的有效性。backtest_single.py 提供单模型的回测功能，支持多种交易策略的模拟；backtest_multi.py 提供多模型的对比回测功能；metrics.py 定义了所有回测评估指标的计算方法；run_backtest.py 是回测的运行入口。回测模块模拟真实的市场交易环境，考虑交易成本、滑点等因素，提供接近实盘的策略评估结果。

### dataset_construction 模块

`dataset_construction/` 目录包含数据收集和构建的工具。news_scraper.py 是新闻数据爬虫，从证券时报等来源抓取财经新闻；price_data_collection.py 提供价格数据的收集功能。这个模块用于构建自定义数据集，对于需要扩展数据范围或使用其他数据源的用户非常有用。爬虫模块依赖 Selenium 和 BeautifulSoup4，需要配置浏览器驱动才能使用。

### dataset 模块

`dataset/` 目录存放项目使用的数据集，包括 CSMD50 和 CSMD300 两个子数据集。每个数据集目录下通常包含：price/ 存放股票价格数据 CSV 文件；news/ 存放新闻文本数据；news_embedding/ 存放预处理后的新闻词向量嵌入；train/、val/、test/ 存放划分后的训练集、验证集和测试集。数据集目录结构遵循项目的约定，正确组织数据是使用项目的前提。

### evaluate 模块

`evaluate/` 目录包含模型评估相关的工具，用于评估模型的可解释性和预测质量。dataset_evaluation.py 提供数据集质量的评估功能。这些工具帮助研究者分析模型行为和数据特性，是进行科学研究的重要辅助模块。

### llm_factor 模块

`llm_factor/` 目录包含利用大语言模型进行因子提取的功能。extract_factors.py 使用 LLM（如 Qwen、GPT 等）从新闻文本中提取金融因子，生成结构化的因子数据。这个模块展示了如何利用最新的 AI 技术增强传统金融数据分析，是项目的特色功能之一。

### single_exp 和 multi_exp 模块

`single_exp/` 和 `multi_exp/` 目录分别包含单模态实验和多模态实验的训练和测试代码。train.py 是训练脚本，test.py 是测试脚本。这两个模块体现了项目对不同数据模态的支持，单模态仅使用价格数据，多模态同时使用价格和新闻数据。

### result 目录

`result/` 目录存放模型训练和回测的结果文件。典型的结构包括：model_saved/ 存放训练好的模型权重文件；figure/ 存放可视化图表；test_result/ 存放测试结果；backtest_result/ 存放回测结果；history_output/ 存放训练历史记录。结果目录的结构与配置参数中的保存路径对应，用户可以在运行时指定自定义的保存位置。

## 核心模块详解

### 数据流架构

数据在项目中按照以下流程流动：原始数据首先从 CSV 文件读取，经过标准化处理后转换为 PyTorch Dataset 对象；Dataset 对象被包装为 DataLoader，提供批量加载和打乱功能；训练循环中，DataLoader 将数据送入模型进行前向传播和反向传播；模型输出经过后处理转换为预测结果；回测模块使用预测结果模拟交易，计算性能指标。整个数据流设计强调高效和可追溯，每个环节都有日志记录便于调试。

### 模型注册机制

项目实现了简单的模型注册机制来支持多种模型。模型通过在 run.py 中直接实例化来使用，而非使用动态注册表。每个模型类都继承 nn.Module 并实现标准的 forward 方法。模型的输入输出格式遵循统一的约定：输入通常是形状为 (batch, seq_len, features) 的张量；输出通常是形状为 (batch, 1) 的概率值或预测值。这种标准化设计使得不同模型可以在相同的代码框架中无缝切换。

### 配置管理

项目使用 argparse 进行命令行参数管理。所有可配置的参数都在 run.py 中定义，包括数据路径、模型参数、训练参数等。参数支持默认值，用户可以通过命令行覆盖。这种方式虽然简单但足够灵活，适合研究场景下频繁调整参数的需求。对于更复杂的配置管理需求，可以考虑集成配置文件（如 YAML 或 JSON）和配置类。

### 实验跟踪

项目使用 SwanLab 进行实验跟踪和可视化。SwanLab 自动记录训练过程中的各项指标，包括损失、准确率、学习率等；支持超参数和配置的版本管理；提供实验对比功能便于分析不同实验；支持远程访问可以在不同设备上查看实验进展。使用 SwanLab 需要配置 API key，默认使用项目提供的 key，生产环境建议使用自己的账户。

## 模块依赖关系

### 依赖图

项目的模块依赖关系如下：run.py 依赖 eval_single.py、eval_multi.py 和 SwanLab；eval_single.py 依赖 utils 模块和 single_exp 模块；eval_multi.py 依赖 utils 模块和 multi_exp 模块；backtest/run_backtest.py 依赖 utils 模块和 backtest 模块；utils 模块内部存在依赖关系，如 price_dataloader.py 和 price_news_dataloader.py 都依赖 pandas、torch 等基础库。理解这些依赖关系有助于定位问题和进行模块替换。

### 数据依赖

数据层面的依赖关系决定了各模块的使用顺序：word2vec.py 依赖 news/ 目录生成 news_embedding/；util.py 依赖 price/ 目录生成训练集、验证集、测试集；run.py 依赖数据预处理的结果进行模型训练；backtest/run_backtest.py 依赖训练好的模型和测试数据进行回测。遵循正确的使用顺序是成功运行项目的关键。

## 设计模式应用

### 工厂模式

数据加载器使用了简单的工厂模式，通过 create_dataset 和 create_dataloader 函数根据输入参数动态创建不同类型的数据集。这种设计使得添加新的数据集类型时无需修改调用代码，只需实现对应的 Dataset 类并在工厂函数中注册即可。

### 策略模式

回测模块应用了策略模式，不同的回测策略（如正常回测、做空回测）通过不同的函数实现。评估指标也采用策略模式，可以灵活组合不同的指标计算方法。这种设计便于扩展新的策略和指标，同时保持核心回测逻辑的稳定。

### 模板方法模式

训练流程使用了模板方法模式，主训练循环在 run.py 中定义，具体的数据加载、模型前向、反向传播等步骤在各个模块中实现。这种设计确保了不同模型训练流程的一致性，同时允许模型特定的训练逻辑存在差异。

## 可扩展性设计

### 添加新模型

要在项目中添加新模型，需要执行以下步骤：在 model/ 目录下创建新模型文件，继承 nn.Module 类；实现 __init__ 方法定义网络结构；实现 forward 方法定义前向传播逻辑；在 run.py 的模型加载部分添加对新模型的支持；可选地在配置参数中添加新模型的特定参数。完成后即可通过 --model 参数指定使用新模型。

### 添加新数据集

要支持新的数据集格式，需要执行以下步骤：创建符合约定格式的数据目录结构；如需特殊的数据预处理，实现对应的处理函数；如需特殊的数据加载逻辑，实现新的 Dataset 类；在数据加载相关代码中注册新数据集类型；更新文档说明新数据集的使用方法。

### 添加新指标

要在回测中添加新的评估指标，需要执行以下步骤：在 backtest/metrics.py 中实现新的指标计算函数；更新回测函数调用新指标；更新结果保存逻辑；更新文档说明新指标的含义和计算方法。

## 版本兼容性

### Python 版本

项目推荐使用 Python 3.10 版本，在 Python 3.8 和 3.11 版本上也能正常工作。较新的 Python 版本通常有更好的性能，但可能存在一些第三方库的兼容性问题。建议使用虚拟环境管理 Python 版本，避免与系统 Python 产生冲突。

### 依赖版本

主要依赖的版本要求如下：PyTorch 2.0 及以上版本支持项目的大部分功能；torchvision 和 torchaudio 版本需要与 PyTorch 版本匹配；numpy 1.24+、pandas 2.0+ 提供数据处理能力；transformers 4.46+ 支持预训练模型加载。requirements.txt 中已指定各依赖的版本，按照该文件安装可以确保环境兼容性。

### CUDA 版本

项目在 CUDA 11.8 和 12.1 版本上测试通过。更早版本的 CUDA 可能存在兼容性问题，特别是对于 vLLM 等依赖。推荐使用 CUDA 11.8，该版本具有最好的生态兼容性。如果遇到 CUDA 相关问题，请参考安装指南中的 CUDA 版本匹配说明。
