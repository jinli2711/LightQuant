# 模型训练

本章节详细介绍 LightQuant 项目的模型训练流程，包括训练环境配置、训练脚本使用、参数调优和训练监控等内容。掌握模型训练是使用 LightQuant 进行股票预测的核心技能。

## 训练环境配置

### GPU 配置

深度学习模型训练通常需要 GPU 加速。首先确认您的系统已正确配置 NVIDIA GPU 和 CUDA 驱动。可以使用以下命令验证 GPU 环境：`python -c "import torch; print(f'CUDA 可用: {torch.cuda.is_available()}'); print(f'GPU 数量: {torch.cuda.device_count()}'); print(f'GPU 名称: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else '无'}")`。如果 CUDA 不可用，请检查安装指南中的 CUDA 配置说明。

GPU 内存管理是训练过程中的重要考虑因素。如果遇到 GPU 内存不足错误，可以尝试：减小 batch_size 参数；启用混合精度训练（如果支持）；使用梯度累积模拟大批量；关闭不必要的进程和程序释放显存。合理规划 GPU 资源使用可以避免内存错误并提高训练效率。

### 实验跟踪配置

LightQuant 使用 SwanLab 进行实验跟踪和可视化。SwanLab 自动记录训练过程中的各项指标，支持实验对比和远程查看。默认配置使用项目提供的 API key，如果您希望使用自己的账户，可以在 `run.py` 中修改以下参数：swanlab_api 设置您的 API key；swanlab_project 设置项目名称；swanlab_workspace 设置工作区名称。

使用 SwanLab 的优势包括：实时监控训练进度和指标变化；自动保存实验配置和超参数；支持多实验对比分析；云端访问便于远程协作。训练开始前会提示登录 SwanLab，登录后即可在网页端查看实验详情。

## 训练脚本使用

### 基本训练命令

项目提供了统一的训练入口脚本 `run.py`。使用多模态数据（价格+新闻）进行训练的典型命令如下：`python run.py --dataset CSMD50 --use_news True --model HAN --epochs 100 --batch_size 64 --lr 3e-4 --look_back_window 7 --hidden_size 128 --attention_size 128 --GPU_ID 0`。此命令将使用 HAN 模型在 CSMD50 数据集上进行多模态训练。

使用单模态数据（仅价格）进行训练的典型命令如下：`python run.py --dataset CSMD50 --use_news False --model LSTM --epochs 100 --batch_size 64 --lr 3e-4 --look_back_window 7 --hidden_size 128 --GPU_ID 0`。单模态训练省略了新闻数据的加载和处理步骤，资源消耗更低。

### 训练流程说明

训练过程按照以下步骤执行：首先初始化随机种子确保结果可复现；然后加载数据集，包括价格数据和（可选的）新闻嵌入数据；接着初始化模型，根据指定的模型名称创建对应的网络结构；之后进入训练循环，每个 epoch 包括前向传播计算损失、反向传播更新参数、验证集评估；最后保存训练好的模型到指定目录。

训练过程中会输出以下信息：当前 epoch 进度和已用时间；训练损失和验证损失；学习率和当前学习率调度状态；GPU 使用情况（显存占用、温度等）；预计剩余时间。密切关注这些输出可以帮助您判断训练是否正常进行。

### 模型选择

项目支持多种预测模型，可以通过 `--model` 参数指定。模型选择建议如下：LSTM 和 BiLSTM 适合作为基线模型，结构简单、易于训练；ALSTM 和 Adv-LSTM 适合需要注意力机制的场景；SCINet 适合长时间序列预测；DTML 适合多股票联合建模；StockNet 和 HAN 适合多模态（价格+新闻）预测；PEN 适合使用预训练金融模型。不同模型的特点和适用场景请参阅模型文档章节。

## 参数配置说明

### 数据参数

数据相关的配置参数包括：dataset 指定数据集名称，如 CSMD50 或 CSMD300；train_price_folder、val_price_folder、test_price_folder 指定价格数据路径；train_news_folder、val_news_folder、test_news_folder 指定新闻嵌入数据路径；use_news 设置是否使用新闻数据（True/False）；look_back_window 设置回看窗口大小，即使用过去多少天的数据预测；batch_size 设置每批次的样本数量。

### 模型参数

模型结构相关的配置参数包括：model 指定使用的模型名称；input_size 设置输入特征数量，默认 5（对应 OHLC 五个价格）；hidden_size 设置隐藏层大小；attention_size 设置注意力机制的大小（适用于 ALSTM、HAN 等模型）；layers 设置网络层数（适用于多层 RNN/LSTM）；dropout 设置 Dropout 比率，用于正则化。

### 训练参数

训练过程相关的配置参数包括：epochs 设置训练轮数；lr 设置学习率；weight_decay 设置权重衰减系数，用于正则化；useGPU 设置是否使用 GPU；GPU_ID 设置使用的 GPU 编号；batch_first 设置输入张量的 batch 维度位置。

### 模型特定参数

不同模型有特定的配置参数：对于 Adv-LSTM，epsilon 设置对抗训练参数，perturbation_size 设置扰动大小；对于 DTML，n_stocks 设置每次训练的股票数量；对于 SCINet，seq_len 设置输入序列长度，pred_len 设置预测长度，SCINet_Layers 设置网络层数；对于 HAN，max_num_tweets_len 设置最大新闻数量，max_num_tokens_len 设置最大 token 数量；对于 PEN，pretrained_model 设置预训练模型路径。

## 超参数调优

### 学习率选择

学习率是最重要的超参数之一，直接影响模型的收敛效果和最终性能。默认学习率为 3e-4，这是一个适合大多数场景的起点。学习率选择的建议如下：如果损失不下降或波动过大，可能是学习率过高；如果损失下降过慢，可能是学习率过低；建议从 1e-5 到 1e-3 范围内尝试；可以使用学习率搜索（learning rate sweep）找到最优值。

学习率调度方面，项目使用余弦退火调度器，学习率会随着训练进程逐渐下降。也可以考虑使用 Early Stopping，在验证集损失不再改善时提前停止训练，避免过拟合。

### 批量大小选择

批量大小影响训练稳定性和效率。较大的批量大小提供更稳定的梯度估计，但需要更多 GPU 内存；较小的批量大小引入更多随机性，可能有助于跳出局部最优，但训练速度较慢。批量大小选择的建议如下：从 32 或 64 开始尝试；根据 GPU 内存调整，最大利用显存的同时留出余量；资源受限时可以使用梯度累积，保持有效批量大小的同时减少显存占用。

### 回看窗口选择

回看窗口（look_back_window）决定模型使用多少天的历史数据。窗口大小的选择需要平衡信息量和噪声：较小的窗口（如 3-5 天）主要捕捉短期趋势；中等窗口（如 7-14 天）平衡短期和中期信息；较大的窗口（如 20 天以上）捕捉长期模式，但可能引入更多噪声。建议从 7 开始尝试，根据验证集表现调整。

### 网络大小选择

隐藏层大小（hidden_size）决定模型的容量。较大的模型有更强的表达能力，但也更容易过拟合。建议从 64 或 128 开始尝试；如果数据量较大，可以尝试 256 或更大；如果出现过拟合迹象，需要减小模型容量或增加正则化。网络层数（layers）同样影响模型容量，双层 LSTM 通常足够应对大多数任务。

## 训练监控与管理

### 损失曲线观察

训练过程中应密切关注损失曲线的变化。正常情况下，训练损失应该逐渐下降，验证损失也应该下降并在某个点趋于稳定。如果出现以下情况需要警惕：训练损失下降但验证损失上升，说明过拟合；两者都剧烈波动，说明学习率可能过高或数据存在问题；损失长时间不下降，可能是学习率过低或模型结构问题。

### 早停机制

建议启用 Early Stopping 机制来防止过拟合。当验证集损失连续若干个 epoch 不再改善时，训练自动停止。LightQuant 默认使用 SwanLab 的实验跟踪，可以配合早停策略使用。早停的耐心值（patience）通常设置为 10-20 个 epoch，既给模型足够的调整时间，又不会过度等待。

### 模型保存

训练过程中会自动保存检查点和最终模型。模型保存路径由 `--model_save_folder` 参数指定，默认为 `./result/{dataset}/model_saved/`。保存的内容包括：模型权重文件（.pth 格式）；完整的模型结构定义；训练配置参数。建议定期备份重要的模型检查点，特别是在进行长时间训练时。

### 实验复现

为确保实验可复现，项目在每次训练开始时设置随机种子。默认种子为 37，可以通过修改 `run.py` 中的 `set_seed` 函数调用来更改。如需完全复现某个实验，需要确保：随机种子一致、软件版本一致、硬件环境一致（包括 GPU 型号和数量）。

## 常见训练问题

### 训练不收敛

如果模型损失长时间不下降，可能的原因和解决方法如下：检查数据是否正确加载和预处理；尝试不同的学习率或优化器；检查模型输入输出维度是否匹配；确认标签生成逻辑是否正确；如果是新添加的模型，检查代码实现是否有错误。

### 过拟合

如果训练损失很低但验证损失较高，说明模型过拟合。解决方法包括：增加 Dropout 比率；减少模型复杂度（hidden_size、layers）；增加训练数据或使用数据增强；使用权重衰减（L2 正则化）；使用 Early Stopping；添加早停机制保存最佳模型。

### 内存不足

如果遇到 CUDA out of memory 错误，解决方法如下：减小 batch_size；启用混合精度训练；减小模型 hidden_size；关闭不必要的进程释放显存；使用梯度累积；如果有多张 GPU，使用多 GPU 并行训练。

### 训练速度慢

如果训练速度不如预期，诊断和优化方法如下：检查 GPU 利用率，可能是数据加载成为瓶颈；增加 num_workers 参数提高数据加载并行度；使用更快的存储设备（如 SSD）；如果仅使用 CPU 训练，考虑使用更小的模型或数据集；检查是否有其他进程占用 GPU 资源。

## 分布式训练

### 多 GPU 训练

LightQuant 支持多 GPU 并行训练以加速大规模实验。启用多 GPU 训练需要：设置 `--useGPU True`；设置 `--GPU_ID` 为可用的 GPU 编号列表或使用所有 GPU；确保 CUDA_VISIBLE_DEVICES 环境变量正确设置。多 GPU 训练通常可以实现接近线性的加速比，但需要注意批量大小的调整。

### 混合精度训练

混合精度训练（AMP）可以显著减少显存占用并加速训练。要启用混合精度训练，需要修改训练代码添加相应的 AMP 逻辑。混合精度训练将部分计算使用 FP16 精度，可以在保持模型质量的同时提高训练效率。启用前请确保您的 GPU 支持 FP16 计算。
