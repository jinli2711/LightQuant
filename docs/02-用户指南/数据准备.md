# 数据准备

本章节详细介绍 LightQuant 项目的数据准备流程，包括数据类型说明、数据格式要求、预处理步骤和数据加载方法。正确的数据准备是使用项目的基础，本文档将帮助您理解并完成数据准备工作。

## 支持的数据类型

LightQuant 项目主要支持以下两类数据：价格数据和新闻数据。价格数据是股票交易的历史记录，包含每个交易日的开盘价、最高价、最低价、收盘价和成交量等信息。新闻数据是影响股票价格的各类资讯，包括新闻标题、发布时间和正文内容。两种数据的结合构成了项目的多模态输入，支持单模态和多模态两种预测模式。

单模态模式仅使用价格数据进行预测，适用于资源受限或仅关注价格技术形态的场景。多模态模式同时使用价格数据和新闻数据，能够捕捉价格模式和消息面的综合影响，通常能获得更好的预测效果。选择哪种模式取决于您的具体需求和可用资源。

## 数据格式说明

### 价格数据格式

价格数据以 CSV 文件格式存储，每只股票对应一个 CSV 文件。文件应包含以下列：Date（日期，格式为 YYYY-MM-DD）、Open（开盘价，浮点数）、High（最高价，浮点数）、Low（最低价，浮点数）、Close（收盘价，浮点数）、Adj Close（调整后收盘价，浮点数）、Volume（成交量，整数）、Label（标签，二分类 0 或 1）。

价格数据的列定义如下：Date 列记录交易的日期，使用标准日期格式以便正确排序和处理；Open、High、Low、Close 是 OHLC 四大价格，反映一天内的价格波动情况；Adj Close 是调整后收盘价，考虑了分红送股等因素的影响，更适合长期分析；Volume 记录当日的交易量，反映市场活跃程度；Label 是预测目标，由下一个交易日收盘价与当前收盘价比较得出。

### 新闻数据格式

新闻数据同样以 CSV 文件格式存储，按股票名称分文件夹组织。每个新闻文件以日期命名，包含当日该股票的所有新闻。文件应包含以下列：time（发布时间，格式为 YYYY-MM-DD HH:MM）、title（新闻标题，字符串）、content（新闻内容，字符串）、link（原文链接，字符串，可选）。

新闻数据的列定义如下：time 列记录新闻发布的精确时间，精确到分钟级别，便于判断新闻与价格变动的时序关系；title 是新闻的标题，通常概括了新闻的核心内容；content 是新闻的正文内容，是进行情感分析和因子提取的主要依据；link 提供原文链接，方便查阅完整新闻。

### 嵌入数据格式

新闻嵌入数据以 NumPy 的 `.npy` 格式存储，是对新闻文本进行向量编码后的结果。嵌入文件的结构与新闻文件对应，每个 `.npy` 文件包含一个二维数组，形状为 (新闻数量, 嵌入维度)。例如，如果一只股票某天有 3 条新闻，嵌入维度为 768，则数组形状为 (3, 768)。使用嵌入数据可以避免重复进行文本编码，提高训练效率。

## 数据目录结构

### 默认目录结构

项目要求数据按照以下目录结构组织：`dataset/{数据集名称}/price/` 存放价格数据 CSV 文件，每个文件以股票名称命名，如 `贵州茅台.csv`；`dataset/{数据集名称}/news/` 存放新闻数据，按股票名称分文件夹组织，如 `dataset/CSMD50/news/贵州茅台/`；`dataset/{数据集名称}/news_embedding/` 存放新闻嵌入数据，结构与新闻目录相同，但文件扩展名为 `.npy`；`dataset/{数据集名称}/train/`、`val/`、`test/` 存放划分后的训练集、验证集和测试集。

### 完整示例目录

以下是 CSMD50 数据集的完整目录示例：`dataset/CSMD50/price/` 下包含贵州茅台.csv、工商银行.csv、恒瑞医药.csv 等 50 个股票价格文件；`dataset/CSMD50/news/` 下包含贵州茅台/、工商银行/、恒瑞医药/ 等子文件夹，每个子文件夹内是以日期命名的 CSV 文件；`dataset/CSMD50/news_embedding/` 的结构与 news 目录相同，但存放 `.npy` 格式的嵌入文件。

## 数据预处理流程

### 第一步：缺失值检查与处理

在开始预处理之前，项目会自动检查数据中的缺失值和异常值。使用以下命令进行缺失值检查：`python utils/util.py --dataset CSMD50 --mode check`。此命令会扫描数据集中的所有 CSV 文件，统计各列的缺失值数量，并输出汇总报告。如果发现缺失值，项目会自动进行填补处理，填补方法为线性插值，对于开头或结尾的缺失值使用前向或后向填充。

缺失值处理的具体方法如下：线性插值适用于连续数据的中间缺失，通过相邻两个有效值的连线估算缺失值；前向填充适用于数据开头部分的缺失，使用最近的有效值填充；后向填充适用于数据结尾部分的缺失，使用前一个有效值填充。处理完成后，项目会再次检查缺失值，确保所有缺失值都已正确处理。

### 第二步：数据划分

处理完缺失值后，需要将数据划分为训练集、验证集和测试集。项目默认按照时间顺序进行划分：训练集包含从数据集开始日期到 2024-03-14 的数据；验证集包含 2024-03-15 到 2024-08-07 的数据；测试集包含 2024-08-08 之后的数据。

划分命令为：`python utils/util.py --dataset CSMD50 --mode split`。此命令会自动创建 train/、val/、test/ 目录，并将对应的数据文件复制到相应目录。划分时，价格数据直接按日期范围划分，新闻数据按日期范围复制到对应目录。划分完成后，后续的训练和测试都应使用划分后的数据。

### 第三步：标签生成

标签是监督学习的目标变量，需要在数据预处理阶段生成。项目使用简单的涨跌标签：如果下一个交易日的收盘价高于当前交易日收盘价，标签为 1；否则标签为 0。标签生成与数据划分同时进行，确保训练集、验证集和测试集中的数据都包含正确的标签。

标签生成使用以下公式：Label(t) = 1 if Close(t+1) > Close(t) else 0。需要注意的是，由于标签需要使用未来信息，原始数据在时间上比实际使用的数据多一天。例如，如果使用 2024-01-01 到 2024-12-31 的数据进行研究，标签计算需要 2025-01-01 的收盘价。划分后的数据集已处理好这一关系，用户无需额外处理。

### 第四步：词向量嵌入生成

对于使用多模态模型的用户，需要生成新闻文本的词向量嵌入。嵌入生成使用 Word2Vec 模型，将每条新闻转换为固定维度的向量。生成命令为：`python utils/word2vec.py --dataset CSMD50 --csv_news_path ./dataset/CSMD50/news/ --embedding_path ./dataset/CSMD50/news_embedding/`。

嵌入生成的过程包括：读取原始新闻数据，进行文本预处理（分词、去停用词等）；使用预训练的词向量模型对每条新闻进行编码；将编码结果保存为 `.npy` 文件。生成过程可能需要较长时间，取决于数据量和 GPU 性能。生成的嵌入文件可以直接被多模态模型加载使用，无需每次训练时重新编码。

## 使用自定义数据集

### 准备价格数据

要使用自定义价格数据，需要按照以下格式准备：创建 CSV 文件，每列对应一个价格字段；日期列使用 YYYY-MM-DD 格式；确保数据按日期升序排列；文件使用 UTF-8 编码。准备完成后，将文件放置在 `dataset/{数据集名称}/price/` 目录下，文件名即为股票名称。

自定义价格数据的质量要求如下：数据完整性要求每个交易日都应有记录，缺失日期应填补或标记；数据准确性要求价格数据应来自可靠来源，避免使用未经验证的数据；数据一致性要求所有股票的数据格式应保持一致，便于统一处理。

### 准备新闻数据

要使用自定义新闻数据，需要按照以下格式准备：为每只股票创建独立的文件夹；每个文件夹内为以日期命名的 CSV 文件；每条新闻包含 time、title、content 字段；文件使用 UTF-8 编码。准备完成后，将文件夹放置在 `dataset/{数据集名称}/news/` 目录下。

自定义新闻数据的质量要求如下：时间准确性要求发布时间字段应准确反映新闻发布时间；内容完整性要求新闻内容应完整包含正文信息；相关性要求新闻应与对应股票相关，避免不相关的信息干扰；去重处理建议去除重复的新闻，避免重复信息影响模型学习。

### 配置数据路径

自定义数据准备好后，需要在运行命令时指定正确的数据路径。主要的配置参数包括：dataset 指定数据集名称；train_price_folder、val_price_folder、test_price_folder 指定价格数据路径；train_news_folder、val_news_folder、test_news_folder 指定新闻数据路径；train_news_folder、val_news_folder、test_news_folder 指定新闻嵌入路径。

示例命令：`python run.py --dataset my_dataset --train_price_folder ./dataset/my_dataset/train/price/ --use_news True --model HAN`。确保所有路径参数正确指向您的自定义数据，否则程序将无法找到数据。

## 数据加载器使用

### 价格数据加载器

项目提供了价格数据加载器 `price_dataloader.py`，用于加载和预处理价格数据。主要的使用方式如下：创建 Normal_Dataset 对象，传入 CSV 文件列表和回看窗口大小；使用 create_dataset 函数从文件夹创建数据集；使用 create_dataloader 函数创建 DataLoader。加载器会自动进行数据标准化和序列分割，将原始数据转换为模型可接受的格式。

数据标准化的计算方法为：标准化值 = (原始值 - 均值) / 标准差。标准化在每只股票的数据上独立进行，确保不同股票的数据具有可比性。标准化参数（均值和标准差）在训练集上计算，应用于验证集和测试集，避免数据泄露。

### 新闻数据加载器

项目提供了新闻数据加载器 `price_news_dataloader.py`，用于同时加载价格和新闻数据进行多模态训练。加载器的使用方式与价格数据加载器类似，但需要同时提供价格数据和新闻嵌入数据的路径。多模态加载器会自动将价格数据和新闻嵌入对齐，确保每个样本的价格和新闻是对应同一天的数据。

### 批量加载配置

DataLoader 支持多种配置参数：batch_size 设置每批次的样本数量；shuffle 设置是否在每个 epoch 后打乱数据；drop_last 设置是否丢弃最后一个不完整的批次；num_workers 设置用于数据加载的进程数。合理的批量大小配置对训练效果和效率都有影响，建议根据 GPU 内存大小进行调整。

## 数据质量检查

### 数据完整性检查

在开始训练之前，建议对数据进行完整性检查。检查内容包括：所有股票文件是否都能正常读取；数据日期范围是否覆盖预期的时间段；是否存在缺失值或异常值；新闻数据与价格数据的对应关系是否正确。可以使用 utils/util.py 中的检查功能进行自动检查。

### 数据分布分析

建议在训练前分析数据的分布特征，包括：价格数据的统计特征（均值、标准差、最值等）；标签的类别分布，检查是否存在严重的类别不平衡；新闻数据的时间分布，检查新闻覆盖是否均匀。分析结果可以帮助您选择合适的模型和参数配置。

### 问题诊断

常见的数据问题及诊断方法如下：如果提示文件找不到，检查文件路径和文件名是否正确；如果提示格式错误，检查 CSV 文件的列名和数据类型是否正确；如果数据量异常，检查是否正确划分了训练集、验证集和测试集；如果标签分布异常，检查标签生成逻辑是否正确。
