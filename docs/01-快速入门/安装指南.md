# 安装指南

本指南详细说明 LightQuant 项目的系统要求、环境配置和安装步骤，帮助您顺利完成开发环境的搭建。

## 系统要求

### 操作系统

LightQuant 项目支持以下操作系统：Windows 10 及以上版本（推荐使用 Windows 11）、Ubuntu 18.04 及以上版本、macOS 10.15 及以上版本。不同操作系统在某些功能上可能存在细微差异，主要体现在环境变量配置和部分依赖的安装方式上。项目主要在 Linux 环境下开发和测试，因此 Linux 系统可以获得最佳支持。Windows 用户建议使用 WSL2（Windows Subsystem for Linux 2）来运行项目，可以避免许多兼容性问题。

### 硬件要求

运行 LightQuant 需要满足以下硬件要求：处理器至少需要四核心 CPU 以支持多任务处理；内存建议 16GB 及以上，运行大型模型训练时可能需要更多内存；存储空间至少需要 50GB 可用空间用于存放数据集、模型和结果；显卡方面，如需进行模型训练，需要 NVIDIA GPU 且支持 CUDA，推荐显存 8GB 及以上。硬件配置越高，能够处理的数据规模和模型复杂度越大，运行速度也越快。对于模型推理（预测）阶段，硬件要求相对较低。

### Python 环境

项目需要 Python 3.8 或更高版本，推荐使用 Python 3.10。安装 Python 前，请确保系统已正确配置环境变量。您可以通过以下命令检查 Python 版本：

```bash
python --version
```

建议使用虚拟环境管理 Python 依赖，可以选择 conda 或 venv。conda 提供了更好的包管理和环境隔离功能，特别适合数据科学项目。使用 conda 创建新环境的命令如下：

```bash
conda create -n lightquant python=3.10
conda activate lightquant
```

## 依赖安装

### 基础依赖

首先，安装项目的基础依赖项。这些是运行 LightQuant 核心功能所必需的包：

```bash
pip install -r requirements.txt
```

`requirements.txt` 文件包含以下主要依赖：numpy 用于数值计算，pandas 用于数据处理，scikit-learn 用于机器学习工具，matplotlib 用于结果可视化，beautifulsoup4 用于网页解析，requests 用于 HTTP 请求，tqdm 用于进度显示，transformers 用于预训练模型，pytorch_lightning 用于模型训练管理，openai 用于 LLM 接口调用，selenium 用于浏览器自动化，modelscope 用于模型管理，swanlab 用于实验跟踪。安装过程中如遇到网络问题，建议使用国内镜像源加速下载。

### PyTorch 安装

requirements.txt 中的 PyTorch 需要单独安装，因为需要选择与您的 CUDA 版本匹配的版本。首先，请确认您的系统已安装正确版本的 NVIDIA 驱动。然后，根据您的 CUDA 版本安装对应的 PyTorch。CUDA 11.8 版本对应的安装命令如下：

```bash
pip install torch==2.4.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

如果您使用 CUDA 12.1，请使用以下命令：

```bash
pip install torch==2.4.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

如需在 CPU 上运行（不推荐用于训练），请安装 CPU 版本：

```bash
pip install torch==2.4.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
```

您可以通过以下命令验证 PyTorch 安装是否正确：

```python
import torch
print(f"PyTorch 版本: {torch.__version__}")
print(f"CUDA 是否可用: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU 设备: {torch.cuda.get_device_name(0)}")
```

### vLLM 安装（可选）

如需使用 LLM 因子提取功能，需要安装 vLLM。vLLM 是一个高效的大语言模型推理库，支持多种模型和优化技术：

```bash
pip install vllm
```

安装 vLLM 需要较高的系统内存和 GPU 显存。如遇到安装问题，请参考 vLLM 官方文档获取详细的安装说明和环境要求。

### 其他注意事项

部分依赖项可能需要系统级库支持。在 Ubuntu 系统上，您可能需要安装以下系统包：

```bash
sudo apt-get update
sudo apt-get install -y libgl1-mesa-glx libglib2.0-0
```

在 Windows 系统上，如使用 Anaconda，大多数系统依赖会自动处理。如果遇到 DLL 相关错误，请尝试安装 Visual C++ Build Tools。

## 验证安装

安装完成后，可以通过以下步骤验证环境是否正确配置。

### 验证 Python 环境

运行以下命令确认 Python 环境正常：

```bash
python -c "import sys; print(f'Python 版本: {sys.version}')"
```

### 验证依赖包

检查主要依赖包是否正确安装：

```bash
python -c "import torch; import pandas; import numpy; import sklearn; print('核心依赖安装成功')"
```

### 运行测试脚本

项目提供了简单的测试脚本用于验证安装：

```bash
python utils/test.py
```

如果测试脚本正常输出且没有报错，说明安装基本成功。如有错误，请根据错误信息排查问题。

## 常见安装问题

### 问题一：pip 安装超时

如果在安装过程中遇到网络超时，可以尝试使用国内镜像源。推荐使用清华大学或阿里云的 pip 镜像：

```bash
pip install 包名 -i https://pypi.tuna.tsinghua.edu.cn/simple
```

或者配置 pip 永久使用镜像源，创建或编辑 `~/.pip/pip.conf` 文件：

```ini
[global]
index-url = https://pypi.tuna.tsinghua.edu.cn/simple
trusted-host = pypi.tuna.tsinghua.edu.cn
```

### 问题二：PyTorch 与 CUDA 版本不匹配

如果 CUDA 不可用或报错，首先检查 CUDA 版本：

```bash
nvcc --version
nvidia-smi
```

然后安装与您的 CUDA 版本匹配的 PyTorch。PyTorch 与 CUDA 版本的对应关系请参考 PyTorch 官方网站。

### 问题三：GPU 内存不足

如果运行模型训练时出现 GPU 内存不足错误，可以尝试以下解决方法：减小批量大小（batch_size）参数；使用梯度累积来模拟大批量训练；启用混合精度训练减少显存占用；如有多张 GPU，使用多 GPU 并行训练。

### 问题四：Windows 环境变量问题

在 Windows 系统上，如果运行命令时提示找不到命令，请检查系统 PATH 环境变量是否包含 Python 和 pip 的路径。通常安装 Python 时会提示是否添加到 PATH，请确保勾选此选项。

### 问题五：导入模块失败

如果在导入模块时遇到类似 "ModuleNotFoundError" 的错误，说明相关依赖未正确安装。请运行 `pip list` 检查依赖包列表，确认所需的包已安装。如果包已安装但仍无法导入，可能是环境问题，尝试重新创建虚拟环境。

## Docker 部署（可选）

对于不想手动配置环境的用户，项目支持使用 Docker 运行。首先，确保您的系统已安装 Docker 和 NVIDIA Docker。然后，使用以下命令构建和运行容器：

```bash
# 构建镜像
docker build -t lightquant .

# 运行容器（需要 GPU 支持）
docker run --gpus all -it -v $(pwd):/app lightquant
```

Docker 环境已预装所有依赖，可以直接使用。详细说明请参考项目中的 Dockerfile。

## 下一步

安装完成后，建议您继续阅读快速开始指南，体验完整的模型训练和回测流程。如果您在使用过程中遇到任何问题，请查阅常见问题页面或通过项目 Issues 寻求帮助。
