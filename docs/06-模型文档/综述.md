# 模型综述

本章节对 LightQuant 项目支持的所有预测模型进行综述，介绍模型分类、设计原理和选择建议，帮助用户理解和选择适合的模型。

## 模型分类

LightQuant 项目支持的模型可以按照多个维度进行分类。按数据模态分类，单模态模型仅使用价格数据，包括 LSTM、BiLSTM、ALSTM、Adv-LSTM、BiGRU、DTML、SCINet；多模态模型同时使用价格和新闻数据，包括 StockNet、HAN、PEN。按网络架构分类，循环神经网络类包括 LSTM、BiLSTM、ALSTM、Adv-LSTM、BiGRU；注意力机制类包括 ALSTM、Adv-LSTM、DTML、HAN；图神经网络类包括 DTML；预训练模型类包括 PEN。按预测任务分类，序列预测模型包括 SCINet、DTML；多模态融合模型包括 StockNet、HAN、PEN。

### 单模态模型

单模态模型仅基于股票历史价格数据进行预测，适合以下场景：资源受限环境，不需要处理文本数据；仅关注技术分析，不考虑消息面影响；需要快速训练和推理；作为基线模型使用。单模态模型的优势在于数据准备简单、训练速度快、资源消耗低。但缺点是只能捕捉价格模式，无法利用新闻信息。

### 多模态模型

多模态模型整合价格数据和新闻文本数据进行联合预测，适合以下场景：有充足的计算资源；需要综合考虑价格和技术面信息；追求更高的预测精度；对模型可解释性有要求。多模态模型的优势在于能够利用更丰富的信息，通常能获得更好的预测效果。但缺点是数据准备复杂、训练时间更长、资源消耗更高。

## 模型选择建议

### 基于数据规模选择

数据规模是模型选择的重要考虑因素。CSMD50 数据集（50 只股票）适合使用简单到中等复杂的模型，如 LSTM、BiLSTM、ALSTM、DTML。CSMD300 数据集（300 只股票）可以尝试更复杂的模型，如 HAN、StockNet、PEN。如果数据量更大（如完整数据集），可以考虑深度模型和复杂架构。

### 基于计算资源选择

GPU 内存是常见的资源限制因素。资源紧张时（GPU 显存 < 4GB）建议使用 LSTM、BiLSTM，批量大小设为 16-32。资源中等时（GPU 显存 4-8GB）可以使用 ALSTM、Adv-LSTM、SCINet，批量大小设为 32-64。资源充足时（GPU 显存 > 8GB）可以使用 HAN、StockNet、PEN，批量大小可以设到 64-128。

### 基于任务目标选择

不同的研究目标适合不同的模型。基准对比实验适合使用 LSTM、BiLSTM，结构简单、易于复现。注意力机制研究适合使用 ALSTM、HAN，可以分析注意力权重的分布。多股票关系建模适合使用 DTML，专门设计用于跨股票联合预测。多模态信息融合适合使用 StockNet、PEN，充分利用文本信息。

### 基于市场特性选择

不同的市场环境可能适合不同的模型。牛市中趋势明显，适合使用能捕捉长期趋势的模型如 SCINet。震荡市中波动频繁，适合使用注意力机制关注关键时点。消息影响大的市场适合使用多模态模型，利用新闻信息辅助决策。流动性差的市场需要注意策略的交易成本影响。

## 性能基准

### CSMD50 数据集基准

以下是各模型在 CSMD50 测试集上的典型性能（仅供参考，实际性能因参数配置而异）：LSTM 准确率约 53.61%，MCC 约 0.0729；BiLSTM 准确率约 53.98%，MCC 约 0.0780；ALSTM 准确率约 54.21%，MCC 约 0.0886；Adv-LSTM 准确率约 54.01%，MCC 约 0.0840；SCINet 准确率约 53.02%，MCC 约 0.0534；DTML 准确率约 54.12%，MCC 约 0.0972；StockNet 准确率约 55.11%，MCC 约 0.0746；HAN 准确率约 54.69%，MCC 约 0.1002；PEN 准确率约 53.12%，MCC 约 0.0582。

### CSMD300 数据集基准

以下是各模型在 CSMD300 测试集上的典型性能：LSTM 准确率约 53.37%，MCC 约 0.0532；BiLSTM 准确率约 53.70%，MCC 约 0.0601；ALSTM 准确率约 53.62%，MCC 约 0.0633；Adv-LSTM 准确率约 54.08%，MCC 约 0.0662；SCINet 准确率约 53.36%，MCC 约 0.0595；DTML 准确率约 54.13%，MCC 约 0.1478；StockNet 准确率约 55.47%，MCC 约 0.0916；HAN 准确率约 55.00%，MCC 约 0.0972；PEN 准确率约 53.27%，MCC 约 0.0893。

### 回测性能基准

以下是各模型在 CSMD50 数据集上的回测性能基准（年化收益率）：LSTM 约 8.84%；BiLSTM 约 8.64%；ALSTM 约 12.03%；Adv-LSTM 约 7.34%；SCINet 约 2.69%；DTML 约 2.28%；StockNet 约 13.01%；HAN 约 7.64%；PEN 约 10.04%。

## 模型复杂度对比

### 参数量对比

不同模型的参数量差异很大。简单模型如 LSTM 的参数量约为 O(4×hidden_size×(input_size+hidden_size)+hidden_size×output_size)；复杂模型如 HAN 的参数量还包括注意力机制和多层网络的参数。以下是各模型典型参数量级估算：LSTM 约 10K-50K 参数；BiLSTM 约 20K-100K 参数；ALSTM 约 20K-150K 参数；SCINet 约 100K-500K 参数；DTML 约 50K-200K 参数；StockNet 约 200K-1M 参数；HAN 约 500K-2M 参数；PEN 约 100M+ 参数（包含 BERT 主体）。

### 计算量对比

训练和推理的计算量影响模型的实际可用性。LSTM 和 BiLSTM 计算效率高，适合快速迭代实验。SCINet 计算量中等，但可以处理较长序列。HAN 和 PEN 计算量最大，需要更多训练时间。DTML 由于涉及多股票联合计算，计算量随股票数量增加。

### 推理速度对比

单样本推理速度（相对值）：LSTM 最快，约 1x；BiLSTM 约 1.5x；ALSTM 约 2x；SCINet 约 3x；DTML 约 5x（取决于股票数量）；StockNet 约 5x；HAN 约 8x；PEN 最慢，约 20x+（包含 BERT 推理）。

## 未来扩展

### 计划支持的模型

项目计划在未来版本中支持的模型包括：Transformer 架构的时序预测模型；图神经网络捕捉股票关联关系；强化学习用于组合优化；多任务学习同时预测多个目标。

### 模型改进方向

现有模型的潜在改进方向包括：模型蒸馏减少计算量；增量学习适应新数据；不确定性量化评估预测置信度；可解释性增强理解模型决策。
